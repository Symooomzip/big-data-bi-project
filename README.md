# ğŸ“Š Big Data & Business Intelligence Project

### Real-Time Data Collection, Sentiment Analysis & PowerBI Dashboards

![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python)
![PowerBI](https://img.shields.io/badge/PowerBI-Dashboard-yellow?logo=powerbi)
![MongoDB](https://img.shields.io/badge/MongoDB-Database-green?logo=mongodb)
![Machine Learning](https://img.shields.io/badge/ML-Scikit--Learn-orange?logo=scikitlearn)

## ğŸ¯ Project Overview

A comprehensive Big Data and Business Intelligence system that collects, processes, analyzes, and visualizes real-time data from multiple sources including social media, financial markets, and news outlets. The project combines data engineering, machine learning, and business intelligence to provide actionable insights.

### Key Components

1. **ğŸ“¡ Data Collection Pipeline** - Real-time scraping from Twitter, Reddit, News, Stock Markets, Economic indicators
2. **ğŸ§¹ Data Processing** - Automated cleaning, transformation, and validation
3. **ğŸ¤– Machine Learning** - Sentiment analysis and predictive models
4. **ğŸ’¾ Database Management** - MongoDB for scalable data storage
5. **ğŸ“Š Business Intelligence** - Interactive PowerBI dashboards
6. **â° Automation** - Scheduled data collection and processing

## âœ¨ Features

### Data Collection

- ğŸ¦ **Twitter Scraper**: Real-time tweets collection using Twikit
- ğŸ”´ **Reddit Scraper**: Posts and comments from relevant subreddits
- ğŸ“° **News Scraper**: Articles from major news sources
- ğŸ“ˆ **Stock Data**: Real-time stock prices (AAPL, GOOGL, MSFT, SPY)
- ğŸ’¹ **Economic Indicators**: Macroeconomic data collection

### Data Processing

- âœ… Data cleaning and validation
- ğŸ”„ Data transformation and normalization
- ğŸ“Š Feature engineering
- ğŸ’¾ MongoDB integration

### Machine Learning

- ğŸ˜Š Sentiment analysis (Positive/Negative/Neutral)
- ğŸ“‰ Predictive modeling with XGBoost
- ğŸ¯ Classification models
- ğŸ“ˆ Time series forecasting

### Business Intelligence

- ğŸ“Š Interactive PowerBI dashboards
- ğŸ“ˆ Real-time data visualization
- ğŸ¨ Custom reports and analytics
- ğŸ“‰ Trend analysis

## ğŸ—ï¸ Project Structure

```
Big-Data-BI-Project/
â”œâ”€â”€ datacol/                          # Data Collection Module
â”‚   â”œâ”€â”€ config/                       # Configuration files
â”‚   â”‚   â”œâ”€â”€ db_config.json
â”‚   â”‚   â”œâ”€â”€ news_config.json
â”‚   â”‚   â”œâ”€â”€ reddit_config.json
â”‚   â”‚   â”œâ”€â”€ stock_config.json
â”‚   â”‚   â””â”€â”€ twitter_config.json
â”‚   â”œâ”€â”€ data/                         # Data storage
â”‚   â”‚   â”œâ”€â”€ raw/                      # Raw collected data
â”‚   â”‚   â””â”€â”€ cleaned/                  # Processed data
â”‚   â”œâ”€â”€ src/                          # Source code
â”‚   â”‚   â”œâ”€â”€ data_collection/          # Scrapers
â”‚   â”‚   â”‚   â”œâ”€â”€ twitter_scraper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ news_scraper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stock_scraper.py
â”‚   â”‚   â”‚   â””â”€â”€ economic_scraper.py
â”‚   â”‚   â”œâ”€â”€ data_processing/          # Data cleaning
â”‚   â”‚   â”‚   â””â”€â”€ clean_data.py
â”‚   â”‚   â”œâ”€â”€ machine_learning/         # ML models
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ mongodb/                  # Database operations
â”‚   â”‚   â”œâ”€â”€ automation/               # Scheduling
â”‚   â”‚   â”‚   â””â”€â”€ schedule_collection.py
â”‚   â”‚   â””â”€â”€ main.py                   # Main entry point
â”‚   â””â”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Project/                          # PowerBI & Reports
â”‚   â”œâ”€â”€ POWERBI+DATASETS/
â”‚   â”‚   â”œâ”€â”€ Project_BI(Fakir_Hamouch).pbix
â”‚   â”‚   â”œâ”€â”€ economic.csv
â”‚   â”‚   â”œâ”€â”€ news.csv
â”‚   â”‚   â”œâ”€â”€ reddit.csv
â”‚   â”‚   â”œâ”€â”€ stock.csv
â”‚   â”‚   â””â”€â”€ twitter.csv
â”‚   â”œâ”€â”€ M1DS-PRESENTATION-(HAMOUCH_FAKIR).pdf
â”‚   â””â”€â”€ M1DS-RAPPORT-POWERBI(HAMOUCH_FAKIR).pdf
â””â”€â”€ documents/                        # Project documentation
    â”œâ”€â”€ M1DS-BI_Projet(FAKIR_HAMOUCH).pdf
    â”œâ”€â”€ M1DS-BigDATA-Projet(HAMOUCH_FAKIR).pdf
    â””â”€â”€ M1DS-REPORT-TraitementMultimedias(HAMOUCH_FAKIR).pdf
```

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- MongoDB (local or cloud instance)
- PowerBI Desktop (for viewing dashboards)
- API Keys for:
  - Twitter API
  - Reddit API
  - News API (optional)

### Step 1: Clone the Repository

```bash
git clone https://github.com/Symooomzip/big-data-bi-project.git
cd big-data-bi-project
```

### Step 2: Set Up Virtual Environment

```bash
# Navigate to datacol directory
cd datacol

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Configure API Keys

Edit the configuration files in `config/` directory:

**config/twitter_config.json**

```json
{
  "api_key": "YOUR_TWITTER_API_KEY",
  "api_secret": "YOUR_TWITTER_API_SECRET",
  "access_token": "YOUR_ACCESS_TOKEN",
  "access_token_secret": "YOUR_ACCESS_TOKEN_SECRET"
}
```

**config/reddit_config.json**

```json
{
  "client_id": "YOUR_REDDIT_CLIENT_ID",
  "client_secret": "YOUR_REDDIT_CLIENT_SECRET",
  "user_agent": "YOUR_USER_AGENT"
}
```

**config/db_config.json**

```json
{
  "mongodb_uri": "mongodb://localhost:27017/",
  "database_name": "big_data_bi"
}
```

### Step 5: Set Up MongoDB

```bash
# Start MongoDB service
# Windows:
net start MongoDB
# Linux:
sudo systemctl start mongod
```

## ğŸ’» Usage

### Data Collection

#### Collect All Data Sources

```bash
cd datacol/src
python main.py
```

#### Collect Specific Data Source

```python
# Twitter data
python data_collection/twitter_scraper.py

# Reddit data
python data_collection/reddit_scraper.py

# Stock data
python data_collection/stock_scraper.py

# News data
python data_collection/news_scraper.py

# Economic data
python data_collection/economic_scraper.py
```

### Data Processing

```bash
# Clean collected data
python data_processing/clean_data.py
```

### Machine Learning

```bash
# Train models
python machine_learning/train.py

# Make predictions
python machine_learning/predict.py
```

### Automated Data Collection

```bash
# Run scheduled collection
python automation/schedule_collection.py
```

### PowerBI Dashboard

1. Open PowerBI Desktop
2. Navigate to `Project/POWERBI+DATASETS/`
3. Open `Project_BI(Fakir_Hamouch).pbix`
4. Refresh data sources if needed

## ğŸ“Š Data Sources

### 1. Twitter Data

- Real-time tweets
- User mentions
- Hashtags
- Sentiment indicators

### 2. Reddit Data

- Posts from finance subreddits
- Comments and discussions
- Upvotes/downvotes
- Community sentiment

### 3. News Articles

- Financial news
- Market analysis
- Company announcements
- Economic reports

### 4. Stock Market Data

- **Stocks**: AAPL, GOOGL, MSFT, SPY
- **Metrics**: Open, High, Low, Close, Volume
- **Frequency**: Real-time/Daily

### 5. Economic Indicators

- GDP data
- Inflation rates
- Employment statistics
- Interest rates

## ğŸ¤– Machine Learning Models

### Sentiment Analysis

- **Algorithm**: Scikit-learn classifiers
- **Features**: Text preprocessing, TF-IDF vectorization
- **Output**: Positive, Negative, Neutral

### Predictive Models

- **Algorithm**: XGBoost
- **Task**: Stock price prediction, trend forecasting
- **Features**: Historical prices, sentiment scores, volume

### Model Performance

- Accuracy metrics tracked in logs
- Cross-validation for robustness
- Regular model retraining

## ğŸ“ˆ PowerBI Dashboards

The PowerBI dashboard includes:

- ğŸ“Š **Overview Dashboard**: Key metrics and KPIs
- ğŸ“ˆ **Stock Analysis**: Price trends and predictions
- ğŸ˜Š **Sentiment Analysis**: Social media sentiment tracking
- ğŸ“° **News Impact**: News correlation with market movements
- ğŸ”„ **Real-time Updates**: Live data refresh

## ğŸ”§ Configuration

### Scheduling Data Collection

Edit `automation/schedule_collection.py` to set collection frequency:

```python
# Collect every hour
schedule.every().hour.do(collect_all_data)

# Collect every day at specific time
schedule.every().day.at("09:00").do(collect_all_data)
```

### Database Configuration

MongoDB connection settings in `config/db_config.json`:

- Connection URI
- Database name
- Collection names

## ğŸ“ API Documentation

### Data Collection Functions

```python
from src.data_collection import twitter_scraper

# Collect tweets
tweets = twitter_scraper.collect_tweets(query="stock market", count=100)

# Save to MongoDB
twitter_scraper.save_to_db(tweets)
```

### Data Processing Functions

```python
from src.data_processing import clean_data

# Clean raw data
cleaned_data = clean_data.process_twitter_data(raw_data)
```

### Machine Learning Functions

```python
from src.machine_learning import predict

# Make prediction
prediction = predict.predict_sentiment(text)
```

## ğŸ› Troubleshooting

### MongoDB Connection Issues

```bash
# Check MongoDB status
mongod --version

# Verify connection
mongo --eval "db.adminCommand('ping')"
```

### API Rate Limits

- Twitter: 450 requests per 15 minutes
- Reddit: 60 requests per minute
- Implement rate limiting in scrapers

### PowerBI Data Refresh

- Ensure CSV files are in correct location
- Update data source paths in PowerBI
- Check file permissions

## ğŸ“š Dependencies

### Core Libraries

- `pandas` - Data manipulation
- `numpy` - Numerical computing
- `pymongo` - MongoDB driver
- `scikit-learn` - Machine learning
- `xgboost` - Gradient boosting
- `matplotlib`, `seaborn` - Visualization

### Data Collection

- `twikit` - Twitter scraping
- `praw` - Reddit API
- `beautifulsoup4` - Web scraping
- `yfinance` - Stock data
- `requests` - HTTP requests

### Automation

- `schedule` - Task scheduling
- `streamlit` - Web dashboard (optional)

## ğŸ“„ Documentation

Detailed documentation available in the `documents/` directory:

- Project proposal
- Technical report
- PowerBI report
- Presentation slides

## ğŸ“ Academic Context

**Course**: M1 Data Science
**Module**: Business Intelligence & Big Data
**Authors**: HAMOUCH & FAKIR
**Institution**: [Your University]

## ğŸ“œ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Data sources: Twitter, Reddit, Yahoo Finance
- Tools: PowerBI, MongoDB, Scikit-learn
- Libraries: See requirements.txt

## ğŸ‘¥ Authors

**HAMOUCH & FAKIR**

- GitHub: [@Symooomzip](https://github.com/Symooomzip)

## ğŸ“§ Contact

For questions or collaboration:

- Email: [mr.fakir.mohammed@gmail.com]
- GitHub Issues: [Project Issues](https://github.com/Symooomzip/big-data-bi-project/issues)

---

**Built with ğŸ’™ for Data Science & Business Intelligence**
